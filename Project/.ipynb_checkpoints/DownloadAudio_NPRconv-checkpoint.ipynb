{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import urllib.request\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "\n",
    "## My codes\n",
    "from src.utils import SoundToText\n",
    "from src.utils import PrepareSound\n",
    "\n",
    "## settings\n",
    "%matplotlib inline\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mData\u001b[m\u001b[m                         README.md\r\n",
      "DownloadAudio_NPR.ipynb      Sentence_to_summary.ipynb\r\n",
      "DownloadAudio_NPRconv.ipynb  Sphinx-VS-Google.ipynb\r\n",
      "DownloadAudio_NPRstory.ipynb Text_to_Suammary.ipynb\r\n",
      "Jun15_MVP.ipynb              all_sum.txt\r\n",
      "Jun8_MVPProcessing.ipynb     all_trans.txt\r\n",
      "Jun8_MVPrecording.ipynb      chunk_s0.wav\r\n",
      "MVP.ipynb                    chunk_s1.wav\r\n",
      "NLP_studies.ipynb            chunk_s2.wav\r\n",
      "\u001b[1m\u001b[36mPlot\u001b[m\u001b[m                         \u001b[1m\u001b[36msrc\u001b[m\u001b[m\r\n",
      "Prev_MVP.ipynb               \u001b[1m\u001b[36mwebsite\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data source:\n",
    "##  NPR: https://www.npr.org/podcasts/2038/news-politics\n",
    "\n",
    "## https://www.npr.org/podcasts/452538677/note-to-self\n",
    "## https://www.npr.org/podcasts/510298/ted-radio-hour\n",
    "\n",
    "## https://www.npr.org/series/4516989/storycorps/archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(open(\"Data/NPR_conv/NoteToSelfNPR.html\"), \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"teaser\">\n",
      "<time datetime=\"2018-06-07\"><span class=\"date\">June 7, 2018 • </span></time>We asked you guys to send us photos. Then we gave them to Andreas Weigend, veteran of Xerox Parc, former chief scientist at Amazon, to see what he could deduce. A lot, it turns out. A little Google image search, a little metadata, and we can find where you are. Maybe who you are. What color phone you're using to take the shot, and how many SIM cards you have. Reading photos is more than a digital parlor trick. It's the future of commerce, marketing, policing, lending, and basically everything else. ------- For the next several weeks you'll hear the \"Best of\" Note to Self in your podcast feed. Our favorite episodes. Manoush will be working on some other projects, but Note to Self will be back before you know it with some changes and surprises. Keep in touch with her on Twitter, Instagram, and on her website.\n",
      "        </p> <li class=\"audio-tool audio-tool-download\"><a data-metrics='{\"category\":\"audio actions\",\"action\":\"download audio\",\"label\":\"617787704\",\"noninteraction\":true}' href=\"https://www.podtrac.com/pts/redirect.mp3/audio.wnyc.org/notetoself/notetoself060718_cms860748_pod.mp3?siteplayer=true&amp;dl=1\"><b class=\"icn-download\"></b><b class=\"audio-tool-label\">Download</b></a>\n",
      "</li>\n"
     ]
    }
   ],
   "source": [
    "pod_text = []\n",
    "pod_audi = []\n",
    "\n",
    "for i in soup.find_all('article', {'class' : 'item podcast-episode'}):\n",
    "#for i in soup.find_all('article', {'class' : 'item has-image'}):\n",
    "    #pods.append(i)\n",
    "    #make sure both audi and text exist for the same episode\n",
    "    for j in i.find_all('p', {'class': 'teaser'}):\n",
    "        pod_text.append(j)\n",
    "    for j in i.find_all('li', {'class': 'audio-tool audio-tool-download'}):\n",
    "        #link = j.find_all('href')\n",
    "        pod_audi.append(j)\n",
    "print(pod_text[0], pod_audi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"teaser\">\n",
      "<time datetime=\"2018-06-07\"><span class=\"date\">June 7, 2018 • </span></time>We asked you guys to send us photos. Then we gave them to Andreas Weigend, veteran of Xerox Parc, former chief scientist at Amazon, to see what he could deduce. A lot, it turns out. A little Google image search, a little metadata, and we can find where you are. Maybe who you are. What color phone you're using to take the shot, and how many SIM cards you have. Reading photos is more than a digital parlor trick. It's the future of commerce, marketing, policing, lending, and basically everything else. ------- For the next several weeks you'll hear the \"Best of\" Note to Self in your podcast feed. Our favorite episodes. Manoush will be working on some other projects, but Note to Self will be back before you know it with some changes and surprises. Keep in touch with her on Twitter, Instagram, and on her website.\n",
      "        </p> <a data-metrics='{\"category\":\"audio actions\",\"action\":\"download audio\",\"label\":\"617787704\",\"noninteraction\":true}' href=\"https://www.podtrac.com/pts/redirect.mp3/audio.wnyc.org/notetoself/notetoself060718_cms860748_pod.mp3?siteplayer=true&amp;dl=1\"><b class=\"icn-download\"></b><b class=\"audio-tool-label\">Download</b></a>\n"
     ]
    }
   ],
   "source": [
    "pod_text = []\n",
    "pod_audi = []\n",
    "\n",
    "for i in soup.find_all('article', {'class' : 'item podcast-episode'}):\n",
    "#for i in soup.find_all('article', {'class' : 'item has-image'}):\n",
    "    #pods.append(i)\n",
    "    #make sure both audi and text exist for the same episode\n",
    "    text = i.find_all('p', {'class': 'teaser'})\n",
    "    audi = i.find_all('li', {'class': 'audio-tool audio-tool-download'})\n",
    "    if len(text) != 1 or len(audi) != 1:\n",
    "        ## no download links...\n",
    "        pass\n",
    "        #print (len(text), len(audi))\n",
    "    else:\n",
    "        pod_text.append(text[0])\n",
    "        pod_audi.append(audi[0].find_all('a', href=True)[0])\n",
    "print(pod_text[0], pod_audi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 96\n"
     ]
    }
   ],
   "source": [
    "print(len(pod_text), len(pod_audi))\n",
    "N = len(pod_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pod_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We asked you guys to send us photos. Then we gave them to Andreas Weigend, veteran of Xerox Parc, former chief scientist at Amazon, to see what he could deduce. A lot, it turns out. A little Google image search, a little metadata, and we can find where you are. Maybe who you are. What color phone you\\'re using to take the shot, and how many SIM cards you have. Reading photos is more than a digital parlor trick. It\\'s the future of commerce, marketing, policing, lending, and basically everything else. ------- For the next several weeks you\\'ll hear the \"Best of\" Note to Self in your podcast feed. Our favorite episodes. Manoush will be working on some other projects, but Note to Self will be back before you know it with some changes and surprises. Keep in touch with her on Twitter, Instagram, and on her website.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get teaser\n",
    "str(t).split(\"</time>\")[1].split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pod_audi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a data-metrics='{\"category\":\"audio actions\",\"action\":\"download audio\",\"label\":\"617787704\",\"noninteraction\":true}' href=\"https://www.podtrac.com/pts/redirect.mp3/audio.wnyc.org/notetoself/notetoself060718_cms860748_pod.mp3?siteplayer=true&amp;dl=1\"><b class=\"icn-download\"></b><b class=\"audio-tool-label\">Download</b></a>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.podtrac.com/pts/redirect.mp3/audio.wnyc.org/notetoself/notetoself060718_cms860748_pod.mp3?siteplayer=true&dl=1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get download link\n",
    "a.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.mp3              30_trans.txt       53.mp3             75.txt\r\n",
      "0.txt              31.mp3             53.txt             75_trans.txt\r\n",
      "0_trans.txt        31.txt             53_trans.txt       76.mp3\r\n",
      "1.mp3              31_trans.txt       54.mp3             76.txt\r\n",
      "1.txt              32.mp3             54.txt             76_trans.txt\r\n",
      "10.mp3             32.txt             54_trans.txt       77.mp3\r\n",
      "10.txt             32_trans.txt       55.mp3             77.txt\r\n",
      "10_trans.txt       33.mp3             55.txt             77_trans.txt\r\n",
      "11.mp3             33.txt             55_trans.txt       78.mp3\r\n",
      "11.txt             33_trans.txt       56.mp3             78.txt\r\n",
      "11_trans.txt       34.mp3             56.txt             78_trans.txt\r\n",
      "12.mp3             34.txt             56_trans.txt       79.mp3\r\n",
      "12.txt             34_trans.txt       57.mp3             79.txt\r\n",
      "12_trans.txt       35.mp3             57.txt             79_trans.txt\r\n",
      "13.mp3             35.txt             57_trans.txt       7_trans.txt\r\n",
      "13.txt             35_trans.txt       58.mp3             8.mp3\r\n",
      "13_trans.txt       36.mp3             58.txt             8.txt\r\n",
      "14.mp3             36.txt             58_trans.txt       80.mp3\r\n",
      "14.txt             36_trans.txt       59.mp3             80.txt\r\n",
      "14_trans.txt       37.mp3             59.txt             80_trans.txt\r\n",
      "15.mp3             37.txt             59_trans.txt       81.mp3\r\n",
      "15.txt             37_trans.txt       5_trans.txt        81.txt\r\n",
      "15_trans.txt       38.mp3             6.mp3              81_trans.txt\r\n",
      "16.mp3             38.txt             6.txt              82.mp3\r\n",
      "16.txt             38_trans.txt       60.mp3             82.txt\r\n",
      "16_trans.txt       39.mp3             60.txt             82_trans.txt\r\n",
      "17.mp3             39.txt             60_trans.txt       83.mp3\r\n",
      "17.txt             39_trans.txt       61.mp3             83.txt\r\n",
      "17_trans.txt       3_trans.txt        61.txt             83_trans.txt\r\n",
      "18.mp3             4.mp3              61_trans.txt       84.mp3\r\n",
      "18.txt             4.txt              62.mp3             84.txt\r\n",
      "18_trans.txt       40.mp3             62.txt             84_trans.txt\r\n",
      "19.mp3             40.txt             62_trans.txt       85.mp3\r\n",
      "19.txt             40_trans.txt       63.mp3             85.txt\r\n",
      "19_trans.txt       41.mp3             63.txt             85_trans.txt\r\n",
      "1_trans.txt        41.txt             63_trans.txt       86.mp3\r\n",
      "2.mp3              41_trans.txt       64.mp3             86.txt\r\n",
      "2.txt              42.mp3             64.txt             86_trans.txt\r\n",
      "20.mp3             42.txt             64_trans.txt       87.mp3\r\n",
      "20.txt             42_trans.txt       65.mp3             87.txt\r\n",
      "20_trans.txt       43.mp3             65.txt             87_trans.txt\r\n",
      "21.mp3             43.txt             65_trans.txt       88.mp3\r\n",
      "21.txt             43_trans.txt       66.mp3             88.txt\r\n",
      "21_trans.txt       44.mp3             66.txt             88_trans.txt\r\n",
      "22.mp3             44.txt             66_trans.txt       89.mp3\r\n",
      "22.txt             44_trans.txt       67.mp3             89.txt\r\n",
      "22_trans.txt       45.mp3             67.txt             89_trans.txt\r\n",
      "23.mp3             45.txt             67_trans.txt       8_trans.txt\r\n",
      "23.txt             45_trans.txt       68.mp3             9.mp3\r\n",
      "23_trans.txt       46.mp3             68.txt             9.txt\r\n",
      "24.mp3             46.txt             68_trans.txt       90.mp3\r\n",
      "24.txt             46_trans.txt       69.mp3             90.txt\r\n",
      "24_trans.txt       47.mp3             69.txt             90_trans.txt\r\n",
      "25.mp3             47.txt             69_trans.txt       91.mp3\r\n",
      "25.txt             47_trans.txt       6_trans.txt        91.txt\r\n",
      "25_trans.txt       48.mp3             7.mp3              91_trans.txt\r\n",
      "26.mp3             48.txt             7.txt              92.mp3\r\n",
      "26.txt             48_trans.txt       70.mp3             92.txt\r\n",
      "26_trans.txt       49.mp3             70.txt             92_trans.txt\r\n",
      "27.mp3             49.txt             70_trans.txt       93.mp3\r\n",
      "27.txt             49_trans.txt       71.mp3             93.txt\r\n",
      "27_trans.txt       4_trans.txt        71.txt             93_trans.txt\r\n",
      "28.mp3             5.mp3              71_trans.txt       94.mp3\r\n",
      "28.txt             5.txt              72.mp3             94.txt\r\n",
      "28_trans.txt       50.mp3             72.txt             94_trans.txt\r\n",
      "29.mp3             50.txt             72_trans.txt       95.mp3\r\n",
      "29.txt             50_trans.txt       73.mp3             95.txt\r\n",
      "29_trans.txt       51.mp3             73.txt             95_trans.txt\r\n",
      "2_trans.txt        51.txt             73_trans.txt       9_trans.txt\r\n",
      "3.mp3              51_trans.txt       74.mp3             NoteToSelfNPR.html\r\n",
      "3.txt              52.mp3             74.txt\r\n",
      "30.mp3             52.txt             74_trans.txt\r\n",
      "30.txt             52_trans.txt       75.mp3\r\n"
     ]
    }
   ],
   "source": [
    "!ls Data/NPR_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [43:47<00:00, 27.37s/it] \n"
     ]
    }
   ],
   "source": [
    "path = \"Data/NPR_conv/\"\n",
    "for i in tqdm(range(0, len(pod_text))):\n",
    "    t = pod_text[i]\n",
    "    ## Get time string\n",
    "    i_time = t.find(\"time\").get(\"datetime\").replace(\"-\", \"\")\n",
    "    ## Get teaser\n",
    "    i_teaser = str(t).split(\"</time>\")[1].split(\"\\n\")[0]\n",
    "    a = pod_audi[i]\n",
    "    ## Get download link\n",
    "    i_url = a.get(\"href\")\n",
    "    \n",
    "    with open(path + str(i) + \".txt\", \"w\") as text_file:\n",
    "        text_file.write(i_teaser)\n",
    "        text_file.write(\"\\n\")\n",
    "        text_file.write(i_time)\n",
    "    \n",
    "    ## download file\n",
    "    output_file = path + str(i) + \".mp3\"\n",
    "    with urllib.request.urlopen(i_url) as response, open(output_file, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response, out_file)\n",
    "\n",
    "#     sound = AudioSegment.from_mp3(output_file)\n",
    "    \n",
    "#     ## split into 20 second pieces\n",
    "#     for j, chunk in enumerate(sound[::20 * 1000]):\n",
    "#       with open(path + str(i) + \"_\" + str(j) + \".wav\", \"wb\") as f:\n",
    "#         chunk.export(f, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Data/NPR_conv/\"\n",
    "bigdic = {}\n",
    "for i in tqdm(range(0, N)):\n",
    "    bigdic.update(PrepareSound(path + str(i) + \".mp3\", silencesplit=True))\n",
    "#     file_path = path ## total \n",
    "#     inputtasks = glob(file_path + str(i) + \"_*.wav\")\n",
    "#     #print(\" Running %s jobs on %s cores\" % (len(inputtasks), mp.cpu_count()-2))\n",
    "#     npool = min(len(inputtasks), mp.cpu_count())\n",
    "#     pool  = mp.Pool(npool)\n",
    "\n",
    "#     fulltextdic = {}\n",
    "#     ## parallel\n",
    "#     for result in pool.map(SoundToText, inputtasks):\n",
    "#             fulltextdic.update(result)\n",
    "# #     ## standard\n",
    "# #     for j in inputtasks:\n",
    "# #         print(j)\n",
    "# #         result = SoundToText(j) #dictionary of values, plots\n",
    "# #         fulltextdic.update(result)\n",
    "    \n",
    "#     for k in inputtasks:\n",
    "#         os.remove(k)\n",
    "        \n",
    "#     fulltext = \"\"\n",
    "#     for l in range(len(fulltextdic.keys())):\n",
    "#         fulltext += fulltextdic[file_path + str(i) + \"_\" + str(l) + \".wav\"] + \" ; \"\n",
    "#     #print(fulltext)\n",
    "#     with open(file_path + str(i) + \"_trans.txt\", \"w\") as text_file:\n",
    "#         text_file.write(fulltext)\n",
    "#     with open(file_path + 'info_' + str(i) + '.pkl', 'wb') as f:\n",
    "#         pickle.dump(fulltextdic, f)\n",
    "#     pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [07:19<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "bigdic = {}\n",
    "for i in tqdm(range(N)):\n",
    "    bigdic.update(PrepareSound(path + str(i) + \".mp3\", silencesplit=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'info.pkl', 'wb') as f:\n",
    "    pickle.dump(bigdic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'info.pkl', 'rb') as f:\n",
    "    mydic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dBFS': -20.927292716731948,\n",
       " 'max_dBFS': -1.1586272649143894,\n",
       " 'duration': 148.89795918367346,\n",
       " 'rms': 2945,\n",
       " 'max': 28676}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydic[path + \"0.wav\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean the tail files\n",
    "#### find *.wav -type f -size -500k -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/426 [01:04<2:30:26, 21.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/3_55.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14/426 [04:53<2:24:04, 20.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/14_53.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 88/426 [30:12<1:56:01, 20.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/88_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 138/426 [47:40<1:39:29, 20.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/138_74.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 159/426 [54:27<1:31:26, 20.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/159_64.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 186/426 [1:04:21<1:23:03, 20.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/186_32.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 230/426 [1:20:10<1:08:19, 20.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/230_48.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 231/426 [1:20:29<1:07:57, 20.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/231_56.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 284/426 [1:40:17<50:08, 21.19s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/284_35.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 289/426 [1:42:09<48:25, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/289_26.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 293/426 [1:43:25<46:56, 21.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/293_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 309/426 [1:49:41<41:32, 21.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/309_49.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 316/426 [1:52:15<39:04, 21.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/316_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 367/426 [2:12:23<21:17, 21.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/367_40.wav\n",
      "cannot recognize  Data/NPR_story/367_44.wav\n",
      "cannot recognize  Data/NPR_story/367_31.wav\n",
      "cannot recognize  Data/NPR_story/367_39.wav\n",
      "cannot recognize  Data/NPR_story/367_34.wav\n",
      "cannot recognize  Data/NPR_story/367_37.wav\n",
      "cannot recognize  Data/NPR_story/367_43.wav\n",
      "cannot recognize  Data/NPR_story/367_47.wav\n",
      "cannot recognize  Data/NPR_story/367_32.wav\n",
      "cannot recognize  Data/NPR_story/367_38.wav\n",
      "cannot recognize  Data/NPR_story/367_48.wav\n",
      "cannot recognize  Data/NPR_story/367_33.wav\n",
      "cannot recognize  Data/NPR_story/367_35.wav\n",
      "cannot recognize  Data/NPR_story/367_42.wav\n",
      "cannot recognize  Data/NPR_story/367_36.wav\n",
      "cannot recognize  Data/NPR_story/367_41.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 382/426 [2:17:58<15:53, 21.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/382_38.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 383/426 [2:18:15<15:31, 21.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/383_81.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 399/426 [2:24:27<09:46, 21.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/399_34.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 406/426 [2:26:31<07:13, 21.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/406_54.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 423/426 [2:32:43<01:04, 21.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot recognize  Data/NPR_story/423_50.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [2:33:52<00:00, 21.67s/it]\n"
     ]
    }
   ],
   "source": [
    "#start_time = time.time()\n",
    "## 228 is missing\n",
    "for i in tqdm(range(0, N)): #len(pod_text) \n",
    "    file_path = path ## total \n",
    "    inputtasks = glob(file_path + str(i) + \"_*.wav\")\n",
    "    #print(\" Running %s jobs on %s cores\" % (len(inputtasks), mp.cpu_count()-2))\n",
    "    npool = min(len(inputtasks), mp.cpu_count()-1)\n",
    "    pool  = mp.Pool(npool)\n",
    "\n",
    "    fulltextdic = {}\n",
    "    ## parallel\n",
    "    for result in pool.map(SoundToText, inputtasks):\n",
    "            fulltextdic.update(result)\n",
    "#     ## standard\n",
    "#     for j in inputtasks:\n",
    "#         print(j)\n",
    "#         result = SoundToText(j) #dictionary of values, plots\n",
    "#         fulltextdic.update(result)\n",
    "    \n",
    "    fulltext = \"\"\n",
    "    for l in range(len(fulltextdic.keys())):\n",
    "        fulltext += fulltextdic[file_path + str(i) + \"_\" + str(l) + \".wav\"] + \" ; \"\n",
    "    #print(fulltext)\n",
    "    with open(file_path + str(i) + \"_trans.txt\", \"w\") as text_file:\n",
    "        text_file.write(fulltext)\n",
    "    with open(file_path + 'info_' + str(i) + '.pkl', 'wb') as f:\n",
    "        pickle.dump(fulltextdic, f)\n",
    "    pool.close()\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
